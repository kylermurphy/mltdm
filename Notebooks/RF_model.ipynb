{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density RF Model \n",
    "\n",
    "Barebones notebook to reproduce the Murphy et al. [2024] density model. \n",
    "\n",
    "Only the model is reproduced, no testing is done (residuals, hyperparameters, permutation importance, etc.). This was done in another set of analysis and removing it here simplifies the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gc\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random state and random forest parameters\n",
    "# random state ensures the same model is generated\n",
    "\n",
    "rnd=17\n",
    "rf_params = {\n",
    "    \"n_estimators\": 500,\n",
    "    \"max_depth\": None,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\":5,\n",
    "    \"warm_start\":False,\n",
    "    \"oob_score\":True,\n",
    "    \"random_state\": rnd,\n",
    "    \"max_features\":0.5,\n",
    "    \"n_jobs\":10\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dat_create(dat, col, log_col, lt_col, y_col, t_col):\n",
    "\n",
    "    x_dat = dat[col+t_col+[y_col]].dropna().copy()\n",
    "\n",
    "    if log_col:\n",
    "       for i in log_col:\n",
    "            try:\n",
    "                x_dat[i] = np.log10(x_dat[i])\n",
    "            except:\n",
    "                print(f'Could not log column {i}')\n",
    "    \n",
    "    if lt_col:\n",
    "        for i in lt_col:\n",
    "            try:\n",
    "                if dat[i].max() > 24:\n",
    "                    x_dat[f'cos_{i}'] = np.cos(dat[i]*2*np.pi/360.)\n",
    "                    x_dat[f'sin_{i}'] = np.sin(dat[i]*2*np.pi/360.)\n",
    "                else:\n",
    "                    x_dat[f'cos_{i}'] = np.cos(dat[i]*2*np.pi/24.)\n",
    "                    x_dat[f'sin_{i}'] = np.sin(dat[i]*2*np.pi/24.)    \n",
    "            except:\n",
    "                print(f'Could not add {i} as a cos/sin time column')\n",
    "    \n",
    "    x_dat = x_dat[~x_dat.isin([np.nan, np.inf, -np.inf]).any(axis=1)].dropna()\n",
    "    y_dat = x_dat[y_col].copy()\n",
    "    x_dat = x_dat.drop(columns=y_col)    \n",
    "    \n",
    "    return x_dat, y_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_model(col=['1300_02', 'SYM_H index','SatLat'], \n",
    "             y_col='400kmDensity', \n",
    "             t_col=['DateTime'], \n",
    "             log_col=['1300_02'], \n",
    "             lt_col=['SatMagLT'], \n",
    "             rf_params=rf_params, \n",
    "             target_dat='D:\\\\data\\\\SatDensities\\\\satdrag_database_grace_B.hdf5', \n",
    "             oos_dat='D:\\\\data\\\\SatDensities\\\\satdrag_database_grace_A.hdf5',\n",
    "             oos_dat2='D:\\\\data\\\\SatDensities\\\\satdrag_database_grace_CHAMP_SI_int.hdf5',\n",
    "             n_repeats=10):\n",
    "    \n",
    "    \n",
    "    rnd = rf_params['random_state']\n",
    "\n",
    "    dat_dic = {'feature_cols':col,\n",
    "               'target_cols':y_col,\n",
    "               'time_cols':t_col,\n",
    "               'log_col':log_col,\n",
    "               'lt_col':lt_col}\n",
    "    \n",
    "    kcol = [col,[y_col],t_col,lt_col]\n",
    "    kflt = [item for sublist in kcol for item in sublist]\n",
    "    df = pd.read_hdf(target_dat)\n",
    "    df = df[kflt].dropna()\n",
    "\n",
    "    reg_x, reg_y = dat_create(dat=df,col=col,log_col=log_col,lt_col=lt_col,\n",
    "                              y_col=y_col,t_col=t_col)\n",
    "    reg_y = reg_y*(10**12)\n",
    "    \n",
    "\n",
    "    # create data set from out of sample data\n",
    "    df_oos = pd.read_hdf(oos_dat)\n",
    "    oos_x, oos_y = dat_create(dat=df_oos,col=col,log_col=log_col,lt_col=lt_col,\n",
    "                              y_col=y_col,t_col=t_col)\n",
    "    oos_y = oos_y*(10**12)\n",
    "    oos_t = oos_x[t_col]\n",
    "    oos_x = oos_x.drop(columns=t_col)\n",
    "    \n",
    "\n",
    "    df_oos2 = pd.read_hdf(oos_dat2)\n",
    "    oos_x2, oos_y2 = dat_create(dat=df_oos2,col=col,log_col=log_col,lt_col=lt_col,\n",
    "                                y_col=y_col,t_col=t_col)\n",
    "    oos_y2 = oos_y2*(10**12)\n",
    "    oos_t2 = oos_x2[t_col]\n",
    "    oos_x2 = oos_x2.drop(columns=t_col)\n",
    "\n",
    "    del df\n",
    "    del df_oos\n",
    "    del df_oos2\n",
    "    gc.collect\n",
    "    \n",
    "    # create train test splits\n",
    "    train_x, test_x, train_y, test_y = train_test_split(reg_x, reg_y, \n",
    "                                                        test_size=0.3, \n",
    "                                                        random_state=rnd)\n",
    "\n",
    "    # get and drop DateTime column\n",
    "    train_t = train_x[t_col].copy()\n",
    "    test_t = test_x[t_col].copy()\n",
    "\n",
    "    train_x = train_x.drop(columns=t_col)\n",
    "    test_x = test_x.drop(columns=t_col)\n",
    "\n",
    "    print('Train and fit model')\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"Time elapsed working on RandomForest\")\n",
    "\n",
    "    rfr = RandomForestRegressor(**rf_params)\n",
    "    rfr.fit(train_x, train_y)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Time consumed in working: \",end - start)\n",
    "\n",
    "    #Make predictions and calculate error\n",
    "    predictions = rfr.predict(test_x)\n",
    "    pre_oos = rfr.predict(oos_x)\n",
    "    pre_oos2 = rfr.predict(oos_x2)\n",
    "    pre_tr = rfr.predict(train_x)\n",
    "    \n",
    "    # combine data sets into single dataframes\n",
    "    train_d = train_x.join([train_y,train_t], how='left')\n",
    "    test_d = test_x.join([test_y,test_t], how='left')\n",
    "    oos_d = oos_x.join([oos_y,oos_t], how='left')\n",
    "    oos2_d = oos_x2.join([oos_y2,oos_t2], how='left')\n",
    "    \n",
    "    # add predictions to the dataframes\n",
    "    train_d[y_col+'_pred'] = pre_tr\n",
    "    test_d[y_col+'_pred'] = predictions\n",
    "    oos_d[y_col+'_pred'] = pre_oos\n",
    "    oos2_d[y_col+'_pred'] = pre_oos2\n",
    "    \n",
    "    \n",
    "    \n",
    "    return rfr, train_d, test_d, oos_d, oos2_d, dat_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_run(y_col='400kmDensity', \n",
    "           lt_col=['SatMagLT'],\n",
    "           pre_f = False,\n",
    "           app_f = False\n",
    "           ):\n",
    "    \"\"\"\n",
    "    Run a set of random forest models \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    \n",
    "    Saves data frames to file for subsequent analysis\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # out_dir \n",
    "    o_dir = 'D:\\\\data\\\\SatDensities\\\\'\n",
    "    \n",
    "    # repeats for permutation importance\n",
    "    n_repeats = 5\n",
    "    # columns that are not used in the model but are returned\n",
    "    # to make subsequent analysis easier\n",
    "    t_col = ['DateTime','storm','storm phase']\n",
    "    \n",
    "    # columns to log for fism and geo datasets\n",
    "    fi_log = ['1300_02', '43000_09', '85550_13', '94400_18']\n",
    "    \n",
    "    # solar indice columns\n",
    "    si_col = ['F10', 'F81', 'S10', 'S81c', 'M10', 'M81c', 'Y10', 'Y81c', 'SatLat']\n",
    "            \n",
    "    # fism2 columns\n",
    "    fi_col = ['1300_02', '43000_09', '85550_13', '94400_18', 'SatLat']\n",
    " \n",
    "    # fism2 and geo columns\n",
    "    fgeo_col = ['1300_02', '43000_09', '85550_13', '94400_18', 'SYM_H index', 'AE', 'SatLat']\n",
    "\n",
    "    # labels\n",
    "    data_labels = ['SI','FI','FI_GEO']\n",
    "    data_sets = [si_col, fi_col, fgeo_col]\n",
    "\n",
    "    data_labels = ['FI_GEO']\n",
    "    data_sets = [fgeo_col]\n",
    "    \n",
    "    for col, d_in in zip(data_sets,data_labels):\n",
    "        \n",
    "        print(d_in)\n",
    "\n",
    "        rf_dat = rf_model(y_col=y_col, lt_col=lt_col,\n",
    "                          col=col, t_col=t_col, log_col=fi_log, \n",
    "                          n_repeats=n_repeats)\n",
    "        \n",
    "        fn = f'{d_in}_RFdat'\n",
    "        if pre_f:\n",
    "            fn = f'{pre_f}{fn}'\n",
    "        if app_f:\n",
    "            fn = f'{fn}{app_f}'\n",
    "            \n",
    "        fn = f'{fn}.pkl'\n",
    "        fn = os.path.join(o_dir,fn)\n",
    "        \n",
    "        with open(fn, 'wb') as f:\n",
    "            pickle.dump(rf_dat, f)\n",
    "            \n",
    "        del rf_dat\n",
    "        gc.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FI_GEO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\murph\\miniconda3\\envs\\satdrag\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\murph\\miniconda3\\envs\\satdrag\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\murph\\miniconda3\\envs\\satdrag\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and fit model\n",
      "Time elapsed working on RandomForest\n",
      "Time consumed in working:  222.15123224258423\n"
     ]
    }
   ],
   "source": [
    "rf_run(app_f='_AIMFAHR')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satdrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
